{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import gc   \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/fourth-expeiments/domain_adaptation_project/continous/slate', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages', '/tmp/tmp9e0iaju9', '/home/guest/Desktop/projects/fourth-expeiments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 05:45:09.929173: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-09 05:45:09.966911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-09 05:45:10.535467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./text-files/\n",
      "./hp-model-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Step 2: Import necessary libraries\n",
    "from typing import Optional, Dict, Any\n",
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rich.traceback import install\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoConfig, get_cosine_schedule_with_warmup\n",
    "from adapters import AutoAdapterModel, AdapterConfig\n",
    "from adapters.composition import Stack\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torchmetrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "install(show_locals=True)\n",
    "\n",
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "print(config.Config.TXT_SAVE_PATH)\n",
    "print(config.Config.MODEL_SAVE_PATH)\n",
    "\n",
    "dataset = load_from_disk(f\"../{config.Config.DATASETS_SAVE_PATH}/datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the DomainTaskAdapter class\n",
    "\n",
    "\n",
    "\n",
    "class DomainTaskAdapter(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(DomainTaskAdapter, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.config = AutoConfig.from_pretrained(self.hparams[\"pretrained_model_name\"])\n",
    "        self.config.output_hidden_states = True\n",
    "        self.model = AutoAdapterModel.from_pretrained(self.hparams[\"pretrained_model_name\"], config=self.config)\n",
    "        \n",
    "        self.reduction_factor = self.hparams.get(\"reduction_factor\", 16)\n",
    "        if self.reduction_factor == \"None\":\n",
    "            self.reduction_factor = 16\n",
    "        self.leave_out = self.hparams.get(\"leave_out\", [])\n",
    "       \n",
    "        self.saved_adapter_dir = self.hparams[\"saved_adapter_dir\"]\n",
    "        self.domain_adapter_name = self.hparams[\"domain_adapter_name\"]\n",
    "        \n",
    "        adapter_config = AdapterConfig.load(\"lora\", r=8, alpha=16)\n",
    "        \n",
    "        self.task_adapter_name = self.hparams[\"task_adapter_name\"]\n",
    "        self.model.add_adapter(self.task_adapter_name, config=adapter_config)\n",
    "\n",
    "        self.model.load_adapter(f\"{self.saved_adapter_dir}/{self.domain_adapter_name}\", with_head=False)\n",
    "        self.model.add_classification_head(self.task_adapter_name, num_labels=self.hparams[\"num_classes\"])\n",
    "        self.model.train_adapter(self.task_adapter_name)\n",
    "\n",
    "        self.model.active_adapters = Stack(self.domain_adapter_name, self.task_adapter_name)\n",
    "\n",
    "        print(self.model.adapter_summary())\n",
    "        print(fn.print_trainable_parameters(self.model))\n",
    "\n",
    "        self.training_outputs = []\n",
    "        self.validation_outputs = []\n",
    "        self.test_outputs = []\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass',                                           \n",
    "                                     num_classes=self.hparams[\"num_classes\"])\n",
    "        self.f1 = torchmetrics.F1Score(task='multiclass',num_classes=self.hparams[\"num_classes\"], average=\"weighted\")\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.entropy_values = []  # For entropy minimization\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask = batch[\"source_input_ids\"], batch[\"source_attention_mask\"]\n",
    "        labels = batch[\"label_source\"]\n",
    "        logits = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        accuracy = self.accuracy(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        f1 = self.f1(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        # self.training_outputs.append({\n",
    "        #     \"train_loss\": loss,\n",
    "        #     \"train_accuracy\":accuracy,\n",
    "        #     \"train_f1\":f1,\n",
    "        #     })\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_accuracy\", accuracy)\n",
    "        self.log(\"train_f1\", f1)\n",
    "        \n",
    "        return loss\n",
    "   \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"validation step of DomainTaskAdapter\"\"\"\n",
    "        # get the input ids and attention mask for source data\n",
    "        input_ids, attention_mask = batch[\"source_input_ids\"], batch[\"source_attention_mask\"]\n",
    "        logits = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        labels = batch[\"label_source\"]\n",
    "        source_loss = self.criterion(logits, labels)\n",
    "        source_accuracy = self.accuracy(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        source_f1 = self.f1(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "\n",
    "\n",
    "        # get the input ids and attention mask for target data\n",
    "        input_ids, attention_mask = batch[\"target_input_ids\"], batch[\"target_attention_mask\"]\n",
    "        logits  = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        labels = batch[\"label_target\"]\n",
    "        target_loss = self.criterion(logits, labels)\n",
    "        target_accuracy = self.accuracy(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        target_f1 = self.f1(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        # # Entropy minimization - calculate and log entropy\n",
    "        # probs = self.softmax(logits).cpu().numpy()\n",
    "        # entropy = -np.sum(probs * np.log(probs + 1e-10), axis=1)\n",
    "        # avg_entropy = np.mean(entropy)\n",
    "        # self.entropy_values.append(avg_entropy)\n",
    "     \n",
    "        # this will log the mean div value across epoch\n",
    "        self.log(name=\"source_val/loss\", value=source_loss, prog_bar=True, logger=True)\n",
    "        self.log(name=\"source_val/accuracy\", value=source_accuracy, prog_bar=True, logger=True)\n",
    "        self.log(name=\"source_val/f1\", value=source_f1, prog_bar=True, logger=True)\n",
    "        self.log(name=\"target_val/loss\", value=target_loss, prog_bar=True, logger=True)\n",
    "        self.log(name=\"target_val/accuracy\", value=target_accuracy, prog_bar=True, logger=True)\n",
    "        self.log(name=\"target_val/f1\", value=target_f1, prog_bar=True, logger=True)\n",
    "        \n",
    "        self.validation_outputs.append({\n",
    "            \"source_val/loss\": source_loss,\n",
    "            \"source_val/accuracy\": source_accuracy,\n",
    "            \"source_val/f1\": source_f1,\n",
    "            \"target_val/loss\": target_loss,\n",
    "            \"target_val/accuracy\": target_accuracy,\n",
    "            \"target_val/f1\": target_f1,\n",
    "            # \"features\": target_features.cpu(),  # Collect features for t-SNE\n",
    "            # \"logits\": logits.cpu(),  # Collect logits for confusion matrix\n",
    "            # \"labels\": labels.cpu()  # Collect labels for confusion matrix   \n",
    "                })\n",
    "        return {\n",
    "            \"source_val/loss\": source_loss,\n",
    "            \"source_val/accuracy\": source_accuracy,\n",
    "            \"source_val/f1\": source_f1,\n",
    "            \"target_val/loss\": target_loss,\n",
    "            \"target_val/accuracy\": target_accuracy,\n",
    "            \"target_val/f1\": target_f1,\n",
    "            # \"features\": target_features.cpu(),  # Collect features for t-SNE\n",
    "            # \"logits\": logits.cpu(),  # Collect logits for confusion matrix\n",
    "            # \"labels\": labels.cpu()  # Collect labels for confusion matrix   \n",
    "                            }\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_outputs = []\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        try:\n",
    "            outputs= self.validation_outputs\n",
    "            mean_source_loss = torch.stack([x[\"source_val/loss\"] for x in outputs]).mean()\n",
    "            mean_source_accuracy = torch.stack([x[\"source_val/accuracy\"] for x in outputs]).mean()\n",
    "            mean_source_f1 = torch.stack([x[\"source_val/f1\"] for x in outputs]).mean()\n",
    "\n",
    "            mean_target_loss = torch.stack([x[\"target_val/loss\"] for x in outputs]).mean()\n",
    "            mean_target_accuracy = torch.stack([x[\"target_val/accuracy\"] for x in outputs]).mean()\n",
    "            mean_target_f1 = torch.stack([x[\"target_val/f1\"] for x in outputs]).mean()\n",
    "            print(f\"target_val/loss: {mean_target_loss}\")\n",
    "            print(f\"target_val/accuracy: {mean_target_accuracy}\")\n",
    "            print(f\"target_val/f1: {mean_target_f1}\")\n",
    "            print(f\"source_val/loss: {mean_source_loss}\")\n",
    "            print(f\"source_val/accuracy: {mean_source_accuracy}\")\n",
    "            print(f\"source_val/f1: {mean_source_f1}\")\n",
    "\n",
    "            self.log(name=\"source_val/loss\", value=mean_source_loss, prog_bar=True, logger=True)\n",
    "            self.log(name=\"source_val/accuracy\", value=mean_source_accuracy, prog_bar=True, logger=True)\n",
    "            self.log(name=\"target_val/loss\", value=mean_target_loss, prog_bar=True, logger=True)\n",
    "            self.log(name=\"target_val/accuracy\", value=mean_target_accuracy, prog_bar=True, logger=True)\n",
    "            self.log(name=\"target_val/f1\", value=mean_target_f1, prog_bar=True, logger=True)\n",
    "            self.log(name=\"source_val/f1\", value=mean_source_f1, prog_bar=True, logger=True)\n",
    "        \n",
    "        \n",
    "            self.log(\"val_loss\", mean_source_loss)\n",
    "            # Generate and log visualizations\n",
    "            # if hasattr(self.trainer, 'current_epoch'):\n",
    "            #     self.plot_tsne(outputs, epoch=self.trainer.current_epoch, phase='validation')\n",
    "            #     self.plot_confusion_matrix(outputs, phase='validation')\n",
    "        except Exception as e:\n",
    "            print(f\"Error during on_validation_epoch_end: {e}\")\n",
    "            raise\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"validation step of DomainTaskAdapter\"\"\"\n",
    "        # get the input ids and attention mask for source data\n",
    "        input_ids, attention_mask = batch[\"source_input_ids\"], batch[\"source_attention_mask\"]\n",
    "        logits  = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        labels = batch[\"label_source\"]\n",
    "        source_loss = self.criterion(logits, labels)\n",
    "        source_accuracy = self.accuracy(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        source_f1 = self.f1(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "\n",
    "        # get the input ids and attention mask for target data\n",
    "        input_ids, attention_mask = batch[\"target_input_ids\"], batch[\"target_attention_mask\"]\n",
    "        logits = self(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        labels = batch[\"label_target\"]\n",
    "        target_loss = self.criterion(logits, labels)\n",
    "        target_accuracy = self.accuracy(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "        target_f1 = self.f1(labels, torch.argmax(self.softmax(logits), dim=1))\n",
    "\n",
    "       \n",
    "\n",
    "        self.log(name=\"source_test/loss\", value=source_loss, logger=True)\n",
    "        self.log(name=\"source_test/accuracy\", value=source_accuracy, logger=True)\n",
    "        self.log(name=\"source_test/f1\", value=source_f1, logger=True)\n",
    "        self.log(name=\"target_test/loss\", value=target_loss, logger=True)\n",
    "        self.log(name=\"target_test/accuracy\", value=target_accuracy, logger=True)\n",
    "        self.log(name=\"target_test/f1\", value=target_f1, logger=True)\n",
    "        \n",
    "        self.test_outputs.append({\n",
    "            \"source_test/loss\": source_loss,\n",
    "            \"source_test/accuracy\": source_accuracy,\n",
    "            \"source_test/f1\": source_f1,\n",
    "            \"target_test/loss\": target_loss,\n",
    "            \"target_test/accuracy\": target_accuracy,\n",
    "            \"target_test/f1\": target_f1,\n",
    "            # \"features\": target_features.cpu(),  # Collect features for t-SNE\n",
    "            # \"logits\": logits.cpu(),  # Collect logits for confusion matrix\n",
    "            # \"labels\": labels.cpu()  # Collect labels for confusion matrix   \n",
    "        })\n",
    "        return {\n",
    "            \"source_test/loss\": source_loss,\n",
    "            \"source_test/accuracy\": source_accuracy,\n",
    "            \"source_test/f1\": source_f1,\n",
    "            \"target_test/loss\": target_loss,\n",
    "            \"target_test/accuracy\": target_accuracy,\n",
    "            \"target_test/f1\": target_f1,\n",
    "            # \"features\": target_features.cpu(),  # Collect features for t-SNE\n",
    "            # \"logits\": logits.cpu(),  # Collect logits for confusion matrix\n",
    "            # \"labels\": labels.cpu()  # Collect labels for confusion matrix   \n",
    "        }\n",
    "    def on_test_epoch_start(self):\n",
    "        self.test_outputs = []\n",
    "    def on_test_epoch_end(self):\n",
    "        try:\n",
    "            outputs=  self.test_outputs\n",
    "            mean_source_loss = torch.stack([x[\"source_test/loss\"] for x in outputs]).mean()\n",
    "            mean_source_accuracy = torch.stack([x[\"source_test/accuracy\"] for x in outputs]).mean()\n",
    "            mean_source_f1 = torch.stack([x[\"source_test/f1\"] for x in outputs]).mean()\n",
    "\n",
    "            mean_target_loss = torch.stack([x[\"target_test/loss\"] for x in outputs]).mean()\n",
    "            mean_target_accuracy = torch.stack([x[\"target_test/accuracy\"] for x in outputs]).mean()\n",
    "            mean_target_f1 = torch.stack([x[\"target_test/f1\"] for x in outputs]).mean()\n",
    "\n",
    "            self.log(name=\"source_test/loss\", value=mean_source_loss)\n",
    "            self.log(name=\"source_test/accuracy\", value=mean_source_accuracy)\n",
    "            self.log(name=\"source_test/f1\", value=mean_source_f1)\n",
    "            self.log(name=\"target_test/loss\", value=mean_target_loss)\n",
    "            self.log(name=\"target_test/accuracy\", value=mean_target_accuracy)\n",
    "            self.log(name=\"target_test/f1\", value=mean_target_f1)\n",
    "\n",
    "            # # Generate and log visualizations\n",
    "            # if hasattr(self.trainer, 'current_epoch'):\n",
    "            #     self.plot_tsne(outputs, epoch=self.trainer.current_epoch, phase='test')\n",
    "            #     self.plot_confusion_matrix(outputs, phase='test')\n",
    "        except Exception as e:\n",
    "            print(f\"Error during on_test_epoch_end: {e}\")\n",
    "            raise\n",
    "    def save_adapter(self, location, adapter_name):\n",
    "        self.model.save_adapter(location, adapter_name)\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams[\"learning_rate\"])\n",
    "        lr_scheduler = {\n",
    "            'scheduler': optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, threshold=0.0001, cooldown=0, min_lr=1e-8),\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    def plot_tsne(self, outputs, epoch, phase):\n",
    "        try:\n",
    "            features = []\n",
    "            labels = []\n",
    "            for output in outputs:\n",
    "                features.extend(output[\"features\"].numpy())  # Use target features\n",
    "                labels.extend(output[\"labels\"].numpy())  # Use target labels\n",
    "\n",
    "            features = np.array(features)\n",
    "            labels = np.array(labels)\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "            # Flatten features if necessary\n",
    "            if features.ndim > 2:\n",
    "                features = features.reshape(features.shape[0], -1)\n",
    "                print(f\"Flattened features shape: {features.shape}\")\n",
    "\n",
    "            tsne = TSNE(n_components=2)\n",
    "            tsne_results = tsne.fit_transform(features)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for i in range(self.hparams[\"num_classes\"]):\n",
    "                idxs = np.where(labels == i)\n",
    "                plt.scatter(tsne_results[idxs, 0], tsne_results[idxs, 1], label=f'Class {i}')\n",
    "            plt.legend()\n",
    "            plt.title(f't-SNE plot {phase} Epoch {epoch}')\n",
    "            plt.show()  # Display the plot inline\n",
    "        except Exception as e:\n",
    "            print(f\"Error during t-SNE plotting: {e}\")\n",
    "            raise\n",
    "\n",
    "    def plot_confusion_matrix(self, outputs, phase):\n",
    "        try:\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            for output in outputs:\n",
    "                y_true.extend(output[\"labels\"].numpy())  # Use target labels\n",
    "                y_pred.extend(torch.argmax(output[\"logits\"], dim=1).numpy())  # Use predicted labels from logits\n",
    "\n",
    "            y_true = np.array(y_true)\n",
    "            y_pred = np.array(y_pred)\n",
    "            print(f\"y_true shape: {y_true.shape}\")\n",
    "            print(f\"y_pred shape: {y_pred.shape}\")\n",
    "\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp.plot()\n",
    "            plt.title(f'Confusion Matrix {phase}')\n",
    "            plt.show()  # Display the plot inline\n",
    "        except Exception as e:\n",
    "            print(f\"Error during confusion matrix plotting: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmrawhani5\u001b[0m (\u001b[33mmrawhani\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Training and Evaluation Loop with Wandb logging\n",
    "import wandb\n",
    "wandb.login()\n",
    "# Wandb setup and training loop\n",
    "seeds = [42,10,100]  # List of seeds\n",
    "project_name = 'final_continous'  # Replace with your wandb project name\n",
    "domain = 'GS'  # Replace with the specific domain for this notebook\n",
    "type = 'invLora_freeze'  # Replace with the specific type for this notebook\n",
    "domain_aprev ='GS'\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {\n",
    "    \"last_epoch\": {\n",
    "        \n",
    "        \"source_test/loss\": [],\n",
    "        \"source_test/accuracy\": [],\n",
    "        \"source_test/f1\": [],\n",
    "        \"target_test/loss\": [],\n",
    "        \"target_test/accuracy\": [],\n",
    "        \"target_test/f1\": [],\n",
    "    },\n",
    "    \"best_model\": {\n",
    "        \n",
    "        \"source_test/loss\": [],\n",
    "        \"source_test/accuracy\": [],\n",
    "        \"source_test/f1\": [],\n",
    "        \"target_test/loss\": [],\n",
    "        \"target_test/accuracy\": [],\n",
    "        \"target_test/f1\": [],\n",
    "    },\n",
    "    \"epoch_saved\": {\n",
    "        \n",
    "        \"source_test/loss\": [],\n",
    "        \"source_test/accuracy\": [],\n",
    "        \"source_test/f1\": [],\n",
    "        \"target_test/loss\": [],\n",
    "        \"target_test/accuracy\": [],\n",
    "        \"target_test/f1\": [],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "best_model_path = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guest/Desktop/projects/fourth-expeiments/domain_adaptation_project/continous/slate/wandb/run-20240709_054512-22hqlvxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mrawhani/final_continous/runs/22hqlvxp' target=\"_blank\">GS_invLora_freeze_run_with_seed_42</a></strong> to <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">https://wandb.ai/mrawhani/final_continous</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mrawhani/final_continous/runs/22hqlvxp' target=\"_blank\">https://wandb.ai/mrawhani/final_continous/runs/22hqlvxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prinssst: government\n",
      "print: slate\n",
      "print: 69575\n",
      "prinssst: government\n",
      "print: slate\n",
      "print: 69575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "task_GS_freeze           lora                294,912       0.269       1       1\n",
      "mlm_inv_S                bottleneck        7,387,776       6.748       1       0\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               109,482,240     100.000               0\n",
      "================================================================================\n",
      "trainable params: 1510461 || all params: 118380477 || trainable%: 1.2759375855530637\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | BertAdapterModel   | 118 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | accuracy  | MulticlassAccuracy | 0     \n",
      "3 | f1        | MulticlassF1Score  | 0     \n",
      "4 | softmax   | Softmax            | 0     \n",
      "-------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "116 M     Non-trainable params\n",
      "118 M     Total params\n",
      "473.522   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ba29dd32f14071aa6b0fd69cacdebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 1.0985016822814941\n",
      "target_val/accuracy: 0.34375\n",
      "target_val/f1: 0.47295671701431274\n",
      "source_val/loss: 1.1050511598587036\n",
      "source_val/accuracy: 0.359375\n",
      "source_val/f1: 0.47651514410972595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c482a513cd44e6d9d66f3ed48e23292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79c58cb9fa049fc8a6e1c7a68a1e59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 0.8002499341964722\n",
      "target_val/accuracy: 0.6551149487495422\n",
      "target_val/f1: 0.6545993685722351\n",
      "source_val/loss: 0.5987363457679749\n",
      "source_val/accuracy: 0.7544652223587036\n",
      "source_val/f1: 0.7538725733757019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a664b0903be9482f9be7d310b1004df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 0.7500745058059692\n",
      "target_val/accuracy: 0.6831774711608887\n",
      "target_val/f1: 0.6825469136238098\n",
      "source_val/loss: 0.5630648732185364\n",
      "source_val/accuracy: 0.7722446918487549\n",
      "source_val/f1: 0.77156001329422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4518b3d4c84b456dacd7cf74ab19df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 0.7186542749404907\n",
      "target_val/accuracy: 0.6997539401054382\n",
      "target_val/f1: 0.6989583373069763\n",
      "source_val/loss: 0.5295063257217407\n",
      "source_val/accuracy: 0.791104793548584\n",
      "source_val/f1: 0.790564775466919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da620c37b63496f88391532e25ef178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 0.7063887119293213\n",
      "target_val/accuracy: 0.710254430770874\n",
      "target_val/f1: 0.7098851799964905\n",
      "source_val/loss: 0.5117101669311523\n",
      "source_val/accuracy: 0.8020334243774414\n",
      "source_val/f1: 0.8017719388008118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f352a37632514b40b2f7edd1efb1a82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 0.6999498605728149\n",
      "target_val/accuracy: 0.7151614427566528\n",
      "target_val/f1: 0.7148067951202393\n",
      "source_val/loss: 0.5058932304382324\n",
      "source_val/accuracy: 0.8028490543365479\n",
      "source_val/f1: 0.8026835322380066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path: ./lightning_logs/22hqlvxp/checkpoints/task-GS-freeze-epoch=04-val_loss=0.51.ckpt\n",
      "Saved epoch checkpoint path: ./lightning_logs/22hqlvxp/checkpoints/GS-freeze-epoch=02.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prinssst: government\n",
      "print: slate\n",
      "print: 69575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91c72bbf1ca4dfcbc181b80fd7a5266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   source_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8119261860847473     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      source_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8116169571876526     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     source_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4894590377807617     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   target_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6973975300788879     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      target_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6964248418807983     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     target_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7318568229675293     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  source_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8119261860847473    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     source_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8116169571876526    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    source_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4894590377807617    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  target_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6973975300788879    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     target_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6964248418807983    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    target_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7318568229675293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results Last Epoch: [{'source_test/loss': 0.4894590377807617, 'source_test/accuracy': 0.8119261860847473, 'source_test/f1': 0.8116169571876526, 'target_test/loss': 0.7318568229675293, 'target_test/accuracy': 0.6973975300788879, 'target_test/f1': 0.6964248418807983}]\n",
      "Best checkpoint path: ./lightning_logs/22hqlvxp/checkpoints/task-GS-freeze-epoch=04-val_loss=0.51.ckpt\n",
      "Saved epoch checkpoint path: ./lightning_logs/22hqlvxp/checkpoints/GS-freeze-epoch=02.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "task_GS_freeze           lora                294,912       0.269       1       1\n",
      "mlm_inv_S                bottleneck        7,387,776       6.748       1       0\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               109,482,240     100.000               0\n",
      "================================================================================\n",
      "trainable params: 1510461 || all params: 118380477 || trainable%: 1.2759375855530637\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5cef22cd9d4538bc833c0bac9e89bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   source_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8119261860847473     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      source_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8116169571876526     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     source_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4894590377807617     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   target_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6973975300788879     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      target_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6964248418807983     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     target_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7318568229675293     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  source_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8119261860847473    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     source_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8116169571876526    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    source_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4894590377807617    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  target_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6973975300788879    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     target_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6964248418807983    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    target_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7318568229675293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results on Best Model: [{'source_test/loss': 0.4894590377807617, 'source_test/accuracy': 0.8119261860847473, 'source_test/f1': 0.8116169571876526, 'target_test/loss': 0.7318568229675293, 'target_test/accuracy': 0.6973975300788879, 'target_test/f1': 0.6964248418807983}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "task_GS_freeze           lora                294,912       0.269       1       1\n",
      "mlm_inv_S                bottleneck        7,387,776       6.748       1       0\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               109,482,240     100.000               0\n",
      "================================================================================\n",
      "trainable params: 1510461 || all params: 118380477 || trainable%: 1.2759375855530637\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e933a9d03fcd46cb86e9a2c29c2f0938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   source_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8003688454627991     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      source_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7994809150695801     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     source_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5055684447288513     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   target_test/accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.677418053150177     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      target_test/f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6764965057373047     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     target_test/loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7519347667694092     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  source_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8003688454627991    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     source_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7994809150695801    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    source_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5055684447288513    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  target_test/accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.677418053150177    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     target_test/f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6764965057373047    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    target_test/loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7519347667694092    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results on saved epoch: [{'source_test/loss': 0.5055684447288513, 'source_test/accuracy': 0.8003688454627991, 'source_test/f1': 0.7994809150695801, 'target_test/loss': 0.7519347667694092, 'target_test/accuracy': 0.677418053150177, 'target_test/f1': 0.6764965057373047}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886a828933414e0aad6a1829ee5e903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇█</td></tr><tr><td>source_test/accuracy</td><td>██▁</td></tr><tr><td>source_test/f1</td><td>██▁</td></tr><tr><td>source_test/loss</td><td>▁▁█</td></tr><tr><td>source_val/accuracy</td><td>▁▄▆██</td></tr><tr><td>source_val/f1</td><td>▁▄▆██</td></tr><tr><td>source_val/loss</td><td>█▅▃▁▁</td></tr><tr><td>target_test/accuracy</td><td>██▁</td></tr><tr><td>target_test/f1</td><td>██▁</td></tr><tr><td>target_test/loss</td><td>▁▁█</td></tr><tr><td>target_val/accuracy</td><td>▁▄▆▇█</td></tr><tr><td>target_val/f1</td><td>▁▄▆▇█</td></tr><tr><td>target_val/loss</td><td>█▄▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▃▅▅▅▅▄▆▆▅█▄▆▄▅▄▇▆▅▅▅▆▅▅▅▄▅▅▄▅▅▆▅▅▅▇▆▅▆</td></tr><tr><td>train_f1</td><td>▁▃▂▄▅▅▅▄▆▅▄█▄▆▄▅▃▇▆▅▄▄▆▅▄▄▃▅▄▄▅▅▆▅▅▅▆▆▅▆</td></tr><tr><td>train_loss</td><td>█▇▆▃▄▂▃▅▂▅▅▁▄▃▆▄▄▁▂▄▄▄▂▄▄▅▅▄▄▄▃▄▄▃▃▄▁▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>source_test/accuracy</td><td>0.80037</td></tr><tr><td>source_test/f1</td><td>0.79948</td></tr><tr><td>source_test/loss</td><td>0.50557</td></tr><tr><td>source_val/accuracy</td><td>0.80285</td></tr><tr><td>source_val/f1</td><td>0.80268</td></tr><tr><td>source_val/loss</td><td>0.50589</td></tr><tr><td>target_test/accuracy</td><td>0.67742</td></tr><tr><td>target_test/f1</td><td>0.6765</td></tr><tr><td>target_test/loss</td><td>0.75193</td></tr><tr><td>target_val/accuracy</td><td>0.71516</td></tr><tr><td>target_val/f1</td><td>0.71481</td></tr><tr><td>target_val/loss</td><td>0.69995</td></tr><tr><td>train_accuracy</td><td>0.84375</td></tr><tr><td>train_f1</td><td>0.84375</td></tr><tr><td>train_loss</td><td>0.46537</td></tr><tr><td>trainer/global_step</td><td>10875</td></tr><tr><td>val_loss</td><td>0.50589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GS_invLora_freeze_run_with_seed_42</strong> at: <a href='https://wandb.ai/mrawhani/final_continous/runs/22hqlvxp' target=\"_blank\">https://wandb.ai/mrawhani/final_continous/runs/22hqlvxp</a><br/> View project at: <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">https://wandb.ai/mrawhani/final_continous</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240709_054512-22hqlvxp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84563c1cce8949b2ae2c0590aabd005d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112934388802388, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guest/Desktop/projects/fourth-expeiments/domain_adaptation_project/continous/slate/wandb/run-20240709_062924-dkm6cw15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mrawhani/final_continous/runs/dkm6cw15' target=\"_blank\">GS_invLora_freeze_run_with_seed_10</a></strong> to <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">https://wandb.ai/mrawhani/final_continous</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mrawhani/final_continous/runs/dkm6cw15' target=\"_blank\">https://wandb.ai/mrawhani/final_continous/runs/dkm6cw15</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 10\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prinssst: government\n",
      "print: slate\n",
      "print: 69575\n",
      "prinssst: government\n",
      "print: slate\n",
      "print: 69575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "/home/guest/.cache/pypoetry/virtualenvs/fourth-experments-OVNdUUAn-py3.8/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "task_GS_freeze           lora                294,912       0.269       1       1\n",
      "mlm_inv_S                bottleneck        7,387,776       6.748       1       0\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               109,482,240     100.000               0\n",
      "================================================================================\n",
      "trainable params: 1510461 || all params: 118380477 || trainable%: 1.2759375855530637\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | BertAdapterModel   | 118 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | accuracy  | MulticlassAccuracy | 0     \n",
      "3 | f1        | MulticlassF1Score  | 0     \n",
      "4 | softmax   | Softmax            | 0     \n",
      "-------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "116 M     Non-trainable params\n",
      "118 M     Total params\n",
      "473.522   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcb99e3337f47a3b95c94a480cee461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val/loss: 1.1053663492202759\n",
      "target_val/accuracy: 0.34375\n",
      "target_val/f1: 0.44190287590026855\n",
      "source_val/loss: 1.0851249694824219\n",
      "source_val/accuracy: 0.421875\n",
      "source_val/f1: 0.5283792018890381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bda278fc6f4d0fa473ff6f31e927f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    wandb.init(project=project_name, name=f'{domain}_{type}_run_with_seed_{seed}', config={'seed': seed})\n",
    "\n",
    "    try:\n",
    "        seed_everything(seed)\n",
    "\n",
    "        hparams = {\n",
    "            \"source_target\": \"government_slate\",\n",
    "            \"source_domain\": \"government\",\n",
    "            \"target_domain\": \"slate\",\n",
    "            \"domain_adapter_name\": \"mlm_inv_S\",\n",
    "            \"task_adapter_name\": \"task_GS_freeze\",\n",
    "            \"pretrained_model_name\": \"bert-base-uncased\",\n",
    "            \"padding\": \"max_length\",\n",
    "            \"max_seq_length\": 128,\n",
    "            \"bsz\": 32,\n",
    "            \"num_classes\": 3,\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"reduction_factor\": 16,\n",
    "            \"mode\": \"domain\",\n",
    "            \"saved_adapter_dir\": \"../../saved/adapters\",\n",
    "        }\n",
    "\n",
    "        save_dir = \"checkpoints\"\n",
    "        save_epoch_3 = 3  # Save model at the 3rd epoch\n",
    "        #save_model_callback_epoch = SaveModelAtEpochCallback(save_dir, save_epoch_3)\n",
    "        # Add a print statement to confirm the callback initialization\n",
    "        #print(f\"Initialized SaveModelAtEpochCallback with save_dir={save_dir} and save_epoch={save_epoch_3}\")\n",
    "        dm = processed.DataModuleSourceTarget(hparams)\n",
    "        dm.setup('fit')\n",
    "        dm.setup(\"test\")\n",
    "\n",
    "        model = DomainTaskAdapter(hparams)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            filename=\"task-GS-freeze-{epoch:02d}-{val_loss:.2f}\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "        )\n",
    "        save_model_callback_epoch = ModelCheckpoint(\n",
    "                # dirpath=checkpoints_path, # <--- specify this on the trainer itself for version control\n",
    "                filename=\"GS-freeze-{epoch:02d}\",\n",
    "                every_n_epochs=save_epoch_3,\n",
    "                save_top_k=-1,  # <--- this is important!\n",
    "            )\n",
    "       \n",
    "        wandb_logger = WandbLogger()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing : {e}\")   \n",
    "\n",
    "    try:\n",
    "        train_loader = dm.train_dataloader()\n",
    "        val_loader = dm.val_dataloader()\n",
    "        trainer = Trainer(\n",
    "            max_epochs=5,\n",
    "            accelerator=\"auto\",\n",
    "            default_root_dir=\"checkpoints\",\n",
    "            # precision=16,\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[checkpoint_callback,save_model_callback_epoch],\n",
    "            limit_train_batches=1.0,\n",
    "            limit_val_batches=1.0,\n",
    "            limit_test_batches=1.0,\n",
    "            # log_every_n_steps=10,\n",
    "        )\n",
    "      \n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "           # After training, print the paths to verify\n",
    "        print(f\"Best checkpoint path: {checkpoint_callback.best_model_path}\")\n",
    "        print(f\"Saved epoch checkpoint path: {save_model_callback_epoch.best_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training : {e}\")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        dm.setup(\"test\")\n",
    "        test_loader = dm.test_dataloader()\n",
    "        test_results_last = trainer.test(model, test_loader)\n",
    "        print(\"Test Results Last Epoch:\", test_results_last)\n",
    "\n",
    "        # Collect results for last epoch model\n",
    "        for key, value in test_results_last[0].items():\n",
    "            results[\"last_epoch\"][key].append(value)\n",
    "\n",
    "        # Paths to the saved checkpoints\n",
    "        best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "        saved_epoch_checkpoint_path = save_model_callback_epoch.best_model_path\n",
    "        # Print the paths to verify\n",
    "        print(f\"Best checkpoint path: {best_checkpoint_path}\")\n",
    "        print(f\"Saved epoch checkpoint path: {saved_epoch_checkpoint_path}\")\n",
    "        \n",
    "        best_model = DomainTaskAdapter.load_from_checkpoint(best_checkpoint_path)\n",
    "        test_results_best = trainer.test(best_model, test_loader)\n",
    "        print(\"Test Results on Best Model:\", test_results_best)\n",
    "        # Collect results for best model\n",
    "        for key, value in test_results_best[0].items():\n",
    "            results[\"best_model\"][key].append(value)\n",
    "\n",
    "        saved_epoch_model = DomainTaskAdapter.load_from_checkpoint(saved_epoch_checkpoint_path)\n",
    "        test_results_saved_epoch = trainer.test(saved_epoch_model, test_loader)\n",
    "        print(\"Test Results on saved epoch:\", test_results_saved_epoch)\n",
    "        # Collect results for 3rd epoch model\n",
    "        for key, value in test_results_saved_epoch[0].items():\n",
    "            results[\"epoch_saved\"][key].append(value)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {e}\")\n",
    "\n",
    "    # Finish the wandb run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('last_epoch', {'source_test/loss': [0.5204232931137085, 0.5499877333641052, 0.5411609411239624], 'source_test/accuracy': [0.8322745561599731, 0.8387089967727661, 0.8322745561599731], 'source_test/f1': [0.8324811458587646, 0.8375324606895447, 0.8314663767814636], 'target_test/loss': [0.8512647151947021, 0.8452407717704773, 0.8509587049484253], 'target_test/accuracy': [0.7295286655426025, 0.7259426116943359, 0.7205327153205872], 'target_test/f1': [0.7310376763343811, 0.7257037162780762, 0.7198448181152344]}), ('best_model', {'source_test/loss': [0.48953601717948914, 0.5020118951797485, 0.477845162153244], 'source_test/accuracy': [0.8153687715530396, 0.810758113861084, 0.8235655426979065], 'source_test/f1': [0.8150216341018677, 0.809558629989624, 0.8223443627357483], 'target_test/loss': [0.7201805114746094, 0.7299922108650208, 0.7292822599411011], 'target_test/accuracy': [0.7203073501586914, 0.7146720886230469, 0.7271925806999207], 'target_test/f1': [0.7197958827018738, 0.7151105999946594, 0.7281570434570312]}), ('epoch_saved', {'source_test/loss': [0.4919324517250061, 0.5038901567459106, 0.477845162153244], 'source_test/accuracy': [0.8368852138519287, 0.8244467377662659, 0.8235655426979065], 'source_test/f1': [0.8363038897514343, 0.8231765031814575, 0.8223443627357483], 'target_test/loss': [0.7397701144218445, 0.7583042979240417, 0.7292822599411011], 'target_test/accuracy': [0.7293851971626282, 0.7200204133987427, 0.7271925806999207], 'target_test/f1': [0.7286763787269592, 0.7205281853675842, 0.7281570434570312]})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guest/Desktop/projects/fourth-expeiments/domain_adaptation_project/continous/slate/wandb/run-20240702_063902-b3k2f8u5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mrawhani/final_continous/runs/b3k2f8u5' target=\"_blank\">GS_mean_results</a></strong> to <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">https://wandb.ai/mrawhani/final_continous</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mrawhani/final_continous/runs/b3k2f8u5' target=\"_blank\">https://wandb.ai/mrawhani/final_continous/runs/b3k2f8u5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90132f460fd14eb7853924241c6b4851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_model/source_test/accuracy</td><td>▁</td></tr><tr><td>best_model/source_test/accuracy_std</td><td>▁</td></tr><tr><td>best_model/source_test/f1</td><td>▁</td></tr><tr><td>best_model/source_test/f1_std</td><td>▁</td></tr><tr><td>best_model/source_test/loss</td><td>▁</td></tr><tr><td>best_model/source_test/loss_std</td><td>▁</td></tr><tr><td>best_model/target_test/accuracy</td><td>▁</td></tr><tr><td>best_model/target_test/accuracy_std</td><td>▁</td></tr><tr><td>best_model/target_test/f1</td><td>▁</td></tr><tr><td>best_model/target_test/f1_std</td><td>▁</td></tr><tr><td>best_model/target_test/loss</td><td>▁</td></tr><tr><td>best_model/target_test/loss_std</td><td>▁</td></tr><tr><td>epoch_saved/source_test/accuracy</td><td>▁</td></tr><tr><td>epoch_saved/source_test/accuracy_std</td><td>▁</td></tr><tr><td>epoch_saved/source_test/f1</td><td>▁</td></tr><tr><td>epoch_saved/source_test/f1_std</td><td>▁</td></tr><tr><td>epoch_saved/source_test/loss</td><td>▁</td></tr><tr><td>epoch_saved/source_test/loss_std</td><td>▁</td></tr><tr><td>epoch_saved/target_test/accuracy</td><td>▁</td></tr><tr><td>epoch_saved/target_test/accuracy_std</td><td>▁</td></tr><tr><td>epoch_saved/target_test/f1</td><td>▁</td></tr><tr><td>epoch_saved/target_test/f1_std</td><td>▁</td></tr><tr><td>epoch_saved/target_test/loss</td><td>▁</td></tr><tr><td>epoch_saved/target_test/loss_std</td><td>▁</td></tr><tr><td>last_epoch/source_test/accuracy</td><td>▁</td></tr><tr><td>last_epoch/source_test/accuracy_std</td><td>▁</td></tr><tr><td>last_epoch/source_test/f1</td><td>▁</td></tr><tr><td>last_epoch/source_test/f1_std</td><td>▁</td></tr><tr><td>last_epoch/source_test/loss</td><td>▁</td></tr><tr><td>last_epoch/source_test/loss_std</td><td>▁</td></tr><tr><td>last_epoch/target_test/accuracy</td><td>▁</td></tr><tr><td>last_epoch/target_test/accuracy_std</td><td>▁</td></tr><tr><td>last_epoch/target_test/f1</td><td>▁</td></tr><tr><td>last_epoch/target_test/f1_std</td><td>▁</td></tr><tr><td>last_epoch/target_test/loss</td><td>▁</td></tr><tr><td>last_epoch/target_test/loss_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model/source_test/accuracy</td><td>0.81656</td></tr><tr><td>best_model/source_test/accuracy_std</td><td>0.0053</td></tr><tr><td>best_model/source_test/f1</td><td>0.81564</td></tr><tr><td>best_model/source_test/f1_std</td><td>0.00524</td></tr><tr><td>best_model/source_test/loss</td><td>0.4898</td></tr><tr><td>best_model/source_test/loss_std</td><td>0.00987</td></tr><tr><td>best_model/target_test/accuracy</td><td>0.72072</td></tr><tr><td>best_model/target_test/accuracy_std</td><td>0.00512</td></tr><tr><td>best_model/target_test/f1</td><td>0.72102</td></tr><tr><td>best_model/target_test/f1_std</td><td>0.0054</td></tr><tr><td>best_model/target_test/loss</td><td>0.72648</td></tr><tr><td>best_model/target_test/loss_std</td><td>0.00447</td></tr><tr><td>epoch_saved/source_test/accuracy</td><td>0.8283</td></tr><tr><td>epoch_saved/source_test/accuracy_std</td><td>0.00608</td></tr><tr><td>epoch_saved/source_test/f1</td><td>0.82727</td></tr><tr><td>epoch_saved/source_test/f1_std</td><td>0.00639</td></tr><tr><td>epoch_saved/source_test/loss</td><td>0.49122</td></tr><tr><td>epoch_saved/source_test/loss_std</td><td>0.01064</td></tr><tr><td>epoch_saved/target_test/accuracy</td><td>0.72553</td></tr><tr><td>epoch_saved/target_test/accuracy_std</td><td>0.004</td></tr><tr><td>epoch_saved/target_test/f1</td><td>0.72579</td></tr><tr><td>epoch_saved/target_test/f1_std</td><td>0.00372</td></tr><tr><td>epoch_saved/target_test/loss</td><td>0.74245</td></tr><tr><td>epoch_saved/target_test/loss_std</td><td>0.012</td></tr><tr><td>last_epoch/source_test/accuracy</td><td>0.83442</td></tr><tr><td>last_epoch/source_test/accuracy_std</td><td>0.00303</td></tr><tr><td>last_epoch/source_test/f1</td><td>0.83383</td></tr><tr><td>last_epoch/source_test/f1_std</td><td>0.00265</td></tr><tr><td>last_epoch/source_test/loss</td><td>0.53719</td></tr><tr><td>last_epoch/source_test/loss_std</td><td>0.01239</td></tr><tr><td>last_epoch/target_test/accuracy</td><td>0.72533</td></tr><tr><td>last_epoch/target_test/accuracy_std</td><td>0.0037</td></tr><tr><td>last_epoch/target_test/f1</td><td>0.72553</td></tr><tr><td>last_epoch/target_test/f1_std</td><td>0.00457</td></tr><tr><td>last_epoch/target_test/loss</td><td>0.84915</td></tr><tr><td>last_epoch/target_test/loss_std</td><td>0.00277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GS_mean_results</strong> at: <a href='https://wandb.ai/mrawhani/final_continous/runs/b3k2f8u5' target=\"_blank\">https://wandb.ai/mrawhani/final_continous/runs/b3k2f8u5</a><br/> View project at: <a href='https://wandb.ai/mrawhani/final_continous' target=\"_blank\">https://wandb.ai/mrawhani/final_continous</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_063902-b3k2f8u5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Results: {'last_epoch': {'source_test/loss': 0.5371906558672587, 'source_test/accuracy': 0.8344193696975708, 'source_test/f1': 0.8338266611099243, 'target_test/loss': 0.8491547306378683, 'target_test/accuracy': 0.7253346641858419, 'target_test/f1': 0.7255287369092306}, 'best_model': {'source_test/loss': 0.4897976915041606, 'source_test/accuracy': 0.81656414270401, 'source_test/f1': 0.8156415422757467, 'target_test/loss': 0.726484994093577, 'target_test/accuracy': 0.7207240064938863, 'target_test/f1': 0.7210211753845215}, 'epoch_saved': {'source_test/loss': 0.4912225902080536, 'source_test/accuracy': 0.8282991647720337, 'source_test/f1': 0.8272749185562134, 'target_test/loss': 0.7424522240956625, 'target_test/accuracy': 0.7255327304204305, 'target_test/f1': 0.7257872025171915}}\n",
      "Standard Deviation Results: {'last_epoch': {'source_test/loss': 0.012391836172645242, 'source_test/accuracy': 0.0030332243936320217, 'source_test/f1': 0.002652942010083325, 'target_test/loss': 0.0027704050340973366, 'target_test/accuracy': 0.0036976551334647876, 'target_test/f1': 0.004571140055691528}, 'best_model': {'source_test/loss': 0.009867762373261401, 'source_test/accuracy': 0.005296492077718203, 'source_test/f1': 0.005238126578072233, 'target_test/loss': 0.0044673544295061925, 'target_test/accuracy': 0.005119953277000895, 'target_test/f1': 0.005396197943788981}, 'epoch_saved': {'source_test/loss': 0.010644665749032738, 'source_test/accuracy': 0.006081902404615396, 'source_test/f1': 0.0063934787121171874, 'target_test/loss': 0.011999026527114707, 'target_test/accuracy': 0.0039992600106207995, 'target_test/f1': 0.0037247257899560766}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and standard deviation for each scenario\n",
    "mean_results = {scenario: {key: np.mean(values) for key, values in metrics.items()} for scenario, metrics in results.items()}\n",
    "std_results = {scenario: {key: np.std(values) for key, values in metrics.items()} for scenario, metrics in results.items()}\n",
    "\n",
    "# Log mean and standard deviation results to wandb\n",
    "wandb.init(project=project_name, name=f'{domain}_mean_results')\n",
    "for scenario in mean_results:\n",
    "    for key, value in mean_results[scenario].items():\n",
    "        wandb.log({f\"{scenario}/{key}\": value})\n",
    "        wandb.log({f\"{scenario}/{key}_std\": std_results[scenario][key]})\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Mean Results:\", mean_results)\n",
    "print(\"Standard Deviation Results:\", std_results)\n",
    "\n",
    "# # Save the best model's adapter\n",
    "# if model:\n",
    "#     adapter_save_path = f\"../../saved/adapter_after_run/{hparams['task_adapter_name']}\"\n",
    "#     model.save_adapter(adapter_save_path, hparams['task_adapter_name'])\n",
    "#     print(f\"Adapter saved to {adapter_save_path}\")\n",
    "# else:\n",
    "#     print(\"No best model to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dones\n"
     ]
    }
   ],
   "source": [
    "print('dones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
