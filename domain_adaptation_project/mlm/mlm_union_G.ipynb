{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/third-experiments/domain_adaptation_project/mlm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/third-experiments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 01:53:29.046822: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 01:53:29.085323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 01:53:29.848279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk,concatenate_datasets\n",
    "\n",
    "\n",
    "adapter_name=\"mlm_union_G\"\n",
    "dataset = load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/datasets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(config)\n",
    "\n",
    "    \n",
    "filtered_target = dataset['train'].filter(lambda example: example['genre'] == \"government\").shuffle(seed=42)\n",
    "#filtered_target = shuffled_filtered_target.train_test_split(test_size=0.1)\n",
    "\n",
    "\n",
    "filtered_test_target = dataset['validation_matched'].filter(lambda example: example['genre'] == \"government\")\n",
    "train_target = filtered_target\n",
    "test_target = filtered_test_target\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109514298 || all params: 109514298 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "init(model)\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "mlm_union_G              union             7,682,688       7.055       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               108,891,648     100.000               0\n",
      "================================================================================\n",
      "trainable params: 8274816 || all params: 117196986 || trainable%: 7.060604783812444\n"
     ]
    }
   ],
   "source": [
    "from adapters import ConfigUnion, LoRAConfig, PrefixTuningConfig, SeqBnConfig,SeqBnInvConfig,AdapterConfig,LoRAConfig\n",
    "\n",
    "union_config = ConfigUnion(\n",
    "    SeqBnInvConfig(reduction_factor=2),\n",
    "    LoRAConfig(r=8, alpha=16),\n",
    ")\n",
    "model.add_adapter(adapter_name, config=union_config)\n",
    "\n",
    "model.train_adapter([adapter_name])\n",
    "model.active_adapters = adapter_name\n",
    "print(model.adapter_summary())\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "    num_rows: 77350\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "reload(processed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.Config.TOKENIZER_NAME)\n",
    "\n",
    "tokenized_dataset= processed.tokenize_dataset(train_target,tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 128\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset[444:470]\n",
    "\n",
    "results = fn.group_texts(tokenized_samples, chunk_size)\n",
    "for chunk in results[\"labels\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "    num_rows: 25770\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we group texts and chunk them\n",
    "lm_datasets = tokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] some investments in stewardship land, for example national parks, will be reported by both 1 ) the number of [MASK] used as a park or an historic site in the stewardship land category, and 2 ) by [MASK] number of physical units identified as national parks in [MASK] heritage assets category. [SEP] [MASK] number of acres used and the number of physical units used on stewardship land are both reported. [SEP] [CLS] the benefits to be gained in air quality [MASK] calculated by epa for [MASK] first six years ( [MASK] the interim program ) to be [MASK] of 125, 000 tons of [MASK]carbons, 2, 388, 000 tons of carbon mono [MASK]'\n",
      "\n",
      "'>>> and 450, 000 [MASK] [MASK] nitrogen [MASK]. [SEP] epa [MASK] that, in the first six years, there baseball be 125 [MASK] 000 fewer tons of hydro [MASK] [MASK]. [SEP] [CLS] 6 trillion. [SEP] 10 trillion [SEP] [CLS] professional training organizations to offer on kelsey campus training at very [SEP] there will now be many places [MASK] [MASK] training. [SEP] [CLS] participants raised [MASK] question [MASK] the current [MASK] of selecting [MASK] needs to be reexamined licence the existing system from a shareholders'point of view has not been working to get the right people on boards. [SEP] 70 % of the participants raised the question whether [MASK] current systemar selecting directors needs to be re'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets[i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "dd=data_collator(samples)\n",
    "for chunk in dd[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 23193\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "downsampled_dataset = lm_datasets.train_test_split(\n",
    "    test_size=0.1, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_mlm_model(model,adapter_name,data_collator,tokenizer, downsampled_dataset['train'],downsampled_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b650e6385054e4e95dc78e75b219de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 16.57\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9fb71414b34b4db03c293359f46152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3193, 'grad_norm': 2.028003454208374, 'learning_rate': 9.84e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25d56e26f02459da0b1a9c3b2bd6c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.006988286972046, 'eval_runtime': 4.4705, 'eval_samples_per_second': 576.447, 'eval_steps_per_second': 18.119, 'epoch': 1.0}\n",
      "{'loss': 2.0442, 'grad_norm': 1.808973789215088, 'learning_rate': 9.322857142857144e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483e28e2d61d42c48026b488d37241b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8463958501815796, 'eval_runtime': 4.4853, 'eval_samples_per_second': 574.542, 'eval_steps_per_second': 18.059, 'epoch': 2.0}\n",
      "{'loss': 1.9471, 'grad_norm': 1.7026065587997437, 'learning_rate': 8.805714285714286e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c8cf8ed6a0479db51d0287fe135638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7995494604110718, 'eval_runtime': 4.5076, 'eval_samples_per_second': 571.698, 'eval_steps_per_second': 17.97, 'epoch': 3.0}\n",
      "{'loss': 1.8908, 'grad_norm': 1.6811236143112183, 'learning_rate': 8.288571428571429e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e6c0cb0fee4a23a2a9c161ade7d11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7943674325942993, 'eval_runtime': 4.5077, 'eval_samples_per_second': 571.684, 'eval_steps_per_second': 17.969, 'epoch': 4.0}\n",
      "{'loss': 1.8573, 'grad_norm': 1.7208678722381592, 'learning_rate': 7.771428571428572e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d45b966c4c49db9c17fc26b40a6481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7475916147232056, 'eval_runtime': 4.4893, 'eval_samples_per_second': 574.032, 'eval_steps_per_second': 18.043, 'epoch': 5.0}\n",
      "{'loss': 1.8234, 'grad_norm': 1.7350397109985352, 'learning_rate': 7.254285714285715e-05, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dadcdc8e9b46229024d3051b705141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7275679111480713, 'eval_runtime': 4.5127, 'eval_samples_per_second': 571.057, 'eval_steps_per_second': 17.949, 'epoch': 6.0}\n",
      "{'loss': 1.803, 'grad_norm': 1.8098242282867432, 'learning_rate': 6.737142857142858e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c9935f99024f16a338e665879d97fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.715086817741394, 'eval_runtime': 4.5136, 'eval_samples_per_second': 570.937, 'eval_steps_per_second': 17.946, 'epoch': 7.0}\n",
      "{'loss': 1.7866, 'grad_norm': 1.687166690826416, 'learning_rate': 6.220000000000001e-05, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b577ba137944fcb31d4d5d084db0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6839878559112549, 'eval_runtime': 4.5236, 'eval_samples_per_second': 569.682, 'eval_steps_per_second': 17.906, 'epoch': 8.0}\n",
      "{'loss': 1.7578, 'grad_norm': 1.771443486213684, 'learning_rate': 5.7035714285714295e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812863efcc08480087f9db82f059473f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6622074842453003, 'eval_runtime': 4.5169, 'eval_samples_per_second': 570.524, 'eval_steps_per_second': 17.933, 'epoch': 9.0}\n",
      "{'loss': 1.7362, 'grad_norm': 1.8516879081726074, 'learning_rate': 5.186428571428572e-05, 'epoch': 9.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81da4d626f0940fb8b5ab9de75943df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6574265956878662, 'eval_runtime': 4.5497, 'eval_samples_per_second': 566.408, 'eval_steps_per_second': 17.803, 'epoch': 10.0}\n",
      "{'loss': 1.7303, 'grad_norm': 1.8219572305679321, 'learning_rate': 4.6692857142857145e-05, 'epoch': 10.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3e17a9d3f947a2a9e3974e5496f980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.677567958831787, 'eval_runtime': 4.4996, 'eval_samples_per_second': 572.718, 'eval_steps_per_second': 18.002, 'epoch': 11.0}\n",
      "{'loss': 1.7165, 'grad_norm': 1.9255632162094116, 'learning_rate': 4.1528571428571425e-05, 'epoch': 11.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdee5ea35fbd448fa188f8e5fd9d2bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6501446962356567, 'eval_runtime': 4.5169, 'eval_samples_per_second': 570.529, 'eval_steps_per_second': 17.933, 'epoch': 12.0}\n",
      "{'loss': 1.7081, 'grad_norm': 1.9021655321121216, 'learning_rate': 3.636428571428572e-05, 'epoch': 12.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585b1ff5d8f3465c8edf5978a1dccec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6561298370361328, 'eval_runtime': 4.5155, 'eval_samples_per_second': 570.703, 'eval_steps_per_second': 17.938, 'epoch': 13.0}\n",
      "{'loss': 1.6873, 'grad_norm': 1.9721722602844238, 'learning_rate': 3.119285714285715e-05, 'epoch': 13.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f367083667f439e820b80dfe808f994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6397020816802979, 'eval_runtime': 4.4981, 'eval_samples_per_second': 572.907, 'eval_steps_per_second': 18.008, 'epoch': 14.0}\n",
      "{'loss': 1.6793, 'grad_norm': 1.9157167673110962, 'learning_rate': 2.6021428571428573e-05, 'epoch': 14.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9bb3a3360a45cc8112a078c172ca57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.619405746459961, 'eval_runtime': 4.503, 'eval_samples_per_second': 572.283, 'eval_steps_per_second': 17.988, 'epoch': 15.0}\n",
      "{'loss': 1.6756, 'grad_norm': 2.0383081436157227, 'learning_rate': 2.085e-05, 'epoch': 15.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a211e4511840dd9856ebba647f1ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6420278549194336, 'eval_runtime': 4.5207, 'eval_samples_per_second': 570.047, 'eval_steps_per_second': 17.918, 'epoch': 16.0}\n",
      "{'loss': 1.6608, 'grad_norm': 1.9698715209960938, 'learning_rate': 1.5685714285714286e-05, 'epoch': 16.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9ed7d06c0b4c1981b1592fa9b2433e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6277962923049927, 'eval_runtime': 4.5171, 'eval_samples_per_second': 570.5, 'eval_steps_per_second': 17.932, 'epoch': 17.0}\n",
      "{'loss': 1.6616, 'grad_norm': 1.9867287874221802, 'learning_rate': 1.0514285714285716e-05, 'epoch': 17.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddf86c4f1eb4c83a2d87fc37565c092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.601144552230835, 'eval_runtime': 4.5183, 'eval_samples_per_second': 570.348, 'eval_steps_per_second': 17.927, 'epoch': 18.0}\n",
      "{'loss': 1.6566, 'grad_norm': 1.9410696029663086, 'learning_rate': 5.342857142857143e-06, 'epoch': 18.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a76030c63749beafba006000825e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.590986728668213, 'eval_runtime': 4.5247, 'eval_samples_per_second': 569.545, 'eval_steps_per_second': 17.902, 'epoch': 19.0}\n",
      "{'loss': 1.659, 'grad_norm': 1.9303500652313232, 'learning_rate': 1.7142857142857143e-07, 'epoch': 19.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f1562e45024f77a7a41fb2e805634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.628571629524231, 'eval_runtime': 4.5008, 'eval_samples_per_second': 572.567, 'eval_steps_per_second': 17.997, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'mlm_union_G'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1844.4316, 'train_samples_per_second': 251.492, 'train_steps_per_second': 7.862, 'train_loss': 1.7898126354875237, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14500, training_loss=1.7898126354875237, metrics={'train_runtime': 1844.4316, 'train_samples_per_second': 251.492, 'train_steps_per_second': 7.862, 'train_loss': 1.7898126354875237, 'epoch': 20.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1286a3740af4400ab29b739ea2f11ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 4.94\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import config.config as config\n",
    "\n",
    "trainer.model.save_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/{adapter_name}\", adapter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a report of mlm for goverment domain using whole genre as target and then splitt after tokenization with seed 42. I used computer metrix for preplexity and early stopping \n",
    "The results before:\n",
    ">>> Perplexity: 16.57\n",
    "\n",
    "The results after:\n",
    ">>> Perplexity: 4.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
