{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/third-experiments/domain_adaptation_project/mlm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/third-experiments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 15:33:53.345518: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 15:33:53.427868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 15:33:54.251170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk,concatenate_datasets\n",
    "\n",
    "\n",
    "adapter_name=\"mlm_inv_G\"\n",
    "dataset = load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/datasets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 34888,\n",
       " 'pairID': '34888e',\n",
       " 'premise': 'The benefits to be gained in air quality were calculated by EPA for the first six years (including the interim program) to be reductions of 125,000 tons of hydrocarbons, 2,388,000 tons of carbon monoxide and 450,000 tons of nitrogen oxide.',\n",
       " 'premise_binary_parse': '( ( The ( benefits ( to ( be ( gained ( in ( air quality ) ) ) ) ) ) ) ( ( were ( ( ( ( calculated ( by EPA ) ) ( for ( the ( first ( six years ) ) ) ) ) ( -LRB- ( ( including ( the ( interim program ) ) ) -RRB- ) ) ) ( to ( be ( reductions ( of ( ( ( ( ( ( 125,000 tons ) ( of hydrocarbons ) ) , ) ( ( 2,388,000 tons ) ( of ( carbon monoxide ) ) ) ) and ) ( ( 450,000 tons ) ( of ( nitrogen oxide ) ) ) ) ) ) ) ) ) ) . ) )',\n",
       " 'premise_parse': '(ROOT (S (NP (DT The) (NNS benefits) (S (VP (TO to) (VP (VB be) (VP (VBN gained) (PP (IN in) (NP (NN air) (NN quality)))))))) (VP (VBD were) (VP (VBN calculated) (PP (IN by) (NP (NNP EPA))) (PP (IN for) (NP (DT the) (JJ first) (CD six) (NNS years))) (PRN (-LRB- -LRB-) (PP (VBG including) (NP (DT the) (JJ interim) (NN program))) (-RRB- -RRB-)) (S (VP (TO to) (VP (VB be) (NP (NP (NNS reductions)) (PP (IN of) (NP (NP (NP (CD 125,000) (NNS tons)) (PP (IN of) (NP (NNS hydrocarbons)))) (, ,) (NP (NP (CD 2,388,000) (NNS tons)) (PP (IN of) (NP (NN carbon) (NN monoxide)))) (CC and) (NP (NP (CD 450,000) (NNS tons)) (PP (IN of) (NP (NN nitrogen) (NN oxide)))))))))))) (. .)))',\n",
       " 'hypothesis': 'EPA estimate that, in the first six years, there will be 125,000 fewer tons of hydrocarbons.',\n",
       " 'hypothesis_binary_parse': '( EPA ( ( estimate ( that ( , ( ( in ( the ( first ( six years ) ) ) ) ( , ( there ( will ( be ( ( 125,000 ( fewer tons ) ) ( of hydrocarbons ) ) ) ) ) ) ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NNP EPA)) (VP (VBP estimate) (SBAR (IN that) (S (, ,) (PP (IN in) (NP (DT the) (JJ first) (CD six) (NNS years))) (, ,) (NP (EX there)) (VP (MD will) (VP (VB be) (NP (NP (CD 125,000) (JJR fewer) (NNS tons)) (PP (IN of) (NP (NNS hydrocarbons))))))))) (. .)))',\n",
       " 'genre': 'government',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(config)\n",
    "\n",
    "    \n",
    "filtered_target = dataset['train'].filter(lambda example: example['genre'] == \"government\").shuffle(seed=42)\n",
    "#filtered_target = shuffled_filtered_target.train_test_split(test_size=0.1)\n",
    "\n",
    "\n",
    "filtered_test_target = dataset['validation_matched'].filter(lambda example: example['genre'] == \"government\")\n",
    "train_target = filtered_target\n",
    "test_target = filtered_test_target\n",
    "train_target[1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109514298 || all params: 109514298 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "init(model)\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "mlm_inv_G                bottleneck        7,387,776       6.785       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               108,891,648     100.000               0\n",
      "================================================================================\n",
      "trainable params: 7979904 || all params: 116902074 || trainable%: 6.82614407679371\n"
     ]
    }
   ],
   "source": [
    "from adapters import ConfigUnion, LoRAConfig, PrefixTuningConfig, SeqBnConfig,SeqBnInvConfig,AdapterConfig,LoRAConfig\n",
    "\n",
    "\n",
    "adapter_config = SeqBnInvConfig(reduction_factor=2)\n",
    "\n",
    "model.add_adapter(adapter_name, config=adapter_config)\n",
    "\n",
    "model.train_adapter([adapter_name])\n",
    "model.active_adapters = adapter_name\n",
    "print(model.adapter_summary())\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "    num_rows: 77350\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "reload(processed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.Config.TOKENIZER_NAME)\n",
    "\n",
    "tokenized_dataset= processed.tokenize_dataset(train_target,tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 128\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset[444:470]\n",
    "\n",
    "results = fn.group_texts(tokenized_samples, chunk_size)\n",
    "for chunk in results[\"labels\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "    num_rows: 25770\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we group texts and chunk them\n",
    "lm_datasets = tokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] some investments in stewardrada land, for example national parks, will be reported by both 1 ) the number of acres used [MASK] [MASK] park or an historic site in the stewardship [MASK] sarcastically, and 2 ) by the number of physical units identified as national parks in the [MASK] assets category. [SEP] [MASK] number [MASK] acres used and [MASK] [MASK] [MASK] physical units [MASK] on [MASK]ship land are both reported. [SEP] [CLS] the benefits to [MASK] gained in [MASK] quality were calculated wholly epa for the first six [MASK] ( including the interim program ) to be reductions of [MASK] [MASK] 000 tons of hydro doubts [MASK], 2, 388, 000 tons of carbon mono [MASK]'\n",
      "\n",
      "'>>> [MASK] 450, 000 tons of nitrogen oxide. [SEP] epa estimate that, in the first six drunken, there will be 125 [MASK] motive fewer tons of hydrocarbons. [SEP] [CLS] 6 trillion. [SEP] organising trillion [SEP] [CLS] professional training organizations [MASK] offer on - campus training [MASK] very [SEP] there will now be many [MASK] to get training. [SEP] [CLS] participants raised the question whether the current system [MASK] selecting directors needs to be reexamined because the existing system from a shareholders'point of view has not been working to [MASK] the right people [MASK] boards. [SEP] 70 % of the participants raised the question whether the current system of selecting directors needs to be re'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets[i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "dd=data_collator(samples)\n",
    "for chunk in dd[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 23193\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "downsampled_dataset = lm_datasets.train_test_split(\n",
    "    test_size=0.1, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_mlm_model(model,adapter_name,data_collator,tokenizer, downsampled_dataset['train'],downsampled_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799e9b0dcd1340aebe82ef0173c7caa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 16.32\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e17834d3f741a4b25360ad756a6cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3227, 'grad_norm': 1.9832983016967773, 'learning_rate': 9.84e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae8e2cdd0fe4411af6be932f943ed27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.014267921447754, 'eval_runtime': 4.1428, 'eval_samples_per_second': 622.04, 'eval_steps_per_second': 19.552, 'epoch': 1.0}\n",
      "{'loss': 2.0522, 'grad_norm': 1.7894372940063477, 'learning_rate': 9.322857142857144e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4420f71e4ed4464d95179aa8c9296b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8555123805999756, 'eval_runtime': 4.16, 'eval_samples_per_second': 619.475, 'eval_steps_per_second': 19.471, 'epoch': 2.0}\n",
      "{'loss': 1.9554, 'grad_norm': 1.7025214433670044, 'learning_rate': 8.805714285714286e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45095da2bcda4bef92db4bc56212dd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8019269704818726, 'eval_runtime': 4.2819, 'eval_samples_per_second': 601.841, 'eval_steps_per_second': 18.917, 'epoch': 3.0}\n",
      "{'loss': 1.8983, 'grad_norm': 1.6784220933914185, 'learning_rate': 8.288571428571429e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be09d2dd5ea4f758da544f1b42bba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8007930517196655, 'eval_runtime': 4.2806, 'eval_samples_per_second': 602.018, 'eval_steps_per_second': 18.923, 'epoch': 4.0}\n",
      "{'loss': 1.8648, 'grad_norm': 1.7432037591934204, 'learning_rate': 7.771428571428572e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764ee4fa82c2465a81c1cc3fdc11e2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7547069787979126, 'eval_runtime': 4.2845, 'eval_samples_per_second': 601.472, 'eval_steps_per_second': 18.905, 'epoch': 5.0}\n",
      "{'loss': 1.8303, 'grad_norm': 1.7076261043548584, 'learning_rate': 7.254285714285715e-05, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f43f748b35464bb6cb6d2ad7c93cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7345521450042725, 'eval_runtime': 4.2717, 'eval_samples_per_second': 603.274, 'eval_steps_per_second': 18.962, 'epoch': 6.0}\n",
      "{'loss': 1.8112, 'grad_norm': 1.7166638374328613, 'learning_rate': 6.737857142857143e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce29a85d5944b4a96be518429b60c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.722590446472168, 'eval_runtime': 4.2462, 'eval_samples_per_second': 606.898, 'eval_steps_per_second': 19.076, 'epoch': 7.0}\n",
      "{'loss': 1.795, 'grad_norm': 1.6718896627426147, 'learning_rate': 6.220714285714286e-05, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8e7e8bf7e74c0e9e85124023b9b771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6912943124771118, 'eval_runtime': 4.2421, 'eval_samples_per_second': 607.481, 'eval_steps_per_second': 19.094, 'epoch': 8.0}\n",
      "{'loss': 1.7654, 'grad_norm': 1.761092185974121, 'learning_rate': 5.7035714285714295e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd32662a7f847399e7e69fd44809766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6711212396621704, 'eval_runtime': 4.237, 'eval_samples_per_second': 608.217, 'eval_steps_per_second': 19.117, 'epoch': 9.0}\n",
      "{'loss': 1.7439, 'grad_norm': 1.8423899412155151, 'learning_rate': 5.186428571428572e-05, 'epoch': 9.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8864e881a1449196282110ee060c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6647063493728638, 'eval_runtime': 4.2628, 'eval_samples_per_second': 604.527, 'eval_steps_per_second': 19.001, 'epoch': 10.0}\n",
      "{'loss': 1.7389, 'grad_norm': 1.8536118268966675, 'learning_rate': 4.6692857142857145e-05, 'epoch': 10.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3f35360b9342d3a7268454e950e54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6875864267349243, 'eval_runtime': 4.2546, 'eval_samples_per_second': 605.699, 'eval_steps_per_second': 19.038, 'epoch': 11.0}\n",
      "{'loss': 1.725, 'grad_norm': 1.8648267984390259, 'learning_rate': 4.1528571428571425e-05, 'epoch': 11.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b783cdc4574170a7945f5bcdd4675f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6571465730667114, 'eval_runtime': 4.2571, 'eval_samples_per_second': 605.348, 'eval_steps_per_second': 19.027, 'epoch': 12.0}\n",
      "{'loss': 1.716, 'grad_norm': 1.9279289245605469, 'learning_rate': 3.6357142857142854e-05, 'epoch': 12.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cb24668ebf4332802f9357a06862fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6658551692962646, 'eval_runtime': 4.265, 'eval_samples_per_second': 604.214, 'eval_steps_per_second': 18.992, 'epoch': 13.0}\n",
      "{'loss': 1.6946, 'grad_norm': 1.9315149784088135, 'learning_rate': 3.118571428571428e-05, 'epoch': 13.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785fd47d448f4e35a8e2f9a9298e3870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.647914171218872, 'eval_runtime': 4.2599, 'eval_samples_per_second': 604.94, 'eval_steps_per_second': 19.014, 'epoch': 14.0}\n",
      "{'loss': 1.6887, 'grad_norm': 1.8841273784637451, 'learning_rate': 2.6021428571428573e-05, 'epoch': 14.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae5f8698a064056b988a847b5c07ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.631975769996643, 'eval_runtime': 4.2509, 'eval_samples_per_second': 606.226, 'eval_steps_per_second': 19.055, 'epoch': 15.0}\n",
      "{'loss': 1.6839, 'grad_norm': 2.0244088172912598, 'learning_rate': 2.085e-05, 'epoch': 15.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea23df45f04f79a75942c6536a1b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6497081518173218, 'eval_runtime': 4.2587, 'eval_samples_per_second': 605.12, 'eval_steps_per_second': 19.02, 'epoch': 16.0}\n",
      "{'loss': 1.6683, 'grad_norm': 1.965439796447754, 'learning_rate': 1.5685714285714286e-05, 'epoch': 16.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e4c23fe6ce4b6ab435aa1996be7cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6360063552856445, 'eval_runtime': 4.2666, 'eval_samples_per_second': 603.998, 'eval_steps_per_second': 18.985, 'epoch': 17.0}\n",
      "{'loss': 1.6695, 'grad_norm': 1.9939582347869873, 'learning_rate': 1.0514285714285716e-05, 'epoch': 17.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92aa85551bbe4a11817cf1e5970001f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6099483966827393, 'eval_runtime': 4.2491, 'eval_samples_per_second': 606.487, 'eval_steps_per_second': 19.063, 'epoch': 18.0}\n",
      "{'loss': 1.6653, 'grad_norm': 1.9110352993011475, 'learning_rate': 5.342857142857143e-06, 'epoch': 18.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb5a16a8c744d8bae868a226108c07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.598004937171936, 'eval_runtime': 4.2534, 'eval_samples_per_second': 605.866, 'eval_steps_per_second': 19.044, 'epoch': 19.0}\n",
      "{'loss': 1.6675, 'grad_norm': 1.905561923980713, 'learning_rate': 1.7857142857142858e-07, 'epoch': 19.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c377d1d356d4ec883a658debc886960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6396472454071045, 'eval_runtime': 4.2582, 'eval_samples_per_second': 605.19, 'eval_steps_per_second': 19.022, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'mlm_inv_G'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1701.892, 'train_samples_per_second': 272.555, 'train_steps_per_second': 8.52, 'train_loss': 1.7976219748135271, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14500, training_loss=1.7976219748135271, metrics={'train_runtime': 1701.892, 'train_samples_per_second': 272.555, 'train_steps_per_second': 8.52, 'train_loss': 1.7976219748135271, 'epoch': 20.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ed1780d7054778bad1823830856034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 4.99\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import config.config as config\n",
    "\n",
    "trainer.model.save_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/{adapter_name}\", adapter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a report of mlm for goverment domain using whole genre as target and then splitt after tokenization with seed 42. I used computer metrix for preplexity and early stopping \n",
    "The results before:\n",
    ">>> Perplexity: 16.32\n",
    "\n",
    "The results after:\n",
    ">>> Perplexity: 4.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
